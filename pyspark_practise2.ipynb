{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyspark in c:\\users\\krish\\anaconda3\\lib\\site-packages (3.0.1)\n",
      "Requirement already satisfied: py4j==0.10.9 in c:\\users\\krish\\anaconda3\\lib\\site-packages (from pyspark) (0.10.9)\n"
     ]
    }
   ],
   "source": [
    "!pip install pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): ...working... done\n",
      "Solving environment: ...working... done\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!conda install -c cyclus java-jdk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark=SparkSession.builder.appName(\"dateanalysis\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "eq=spark.read.csv(\"C:/Users/krish/OneDrive/Documents/UoH/datasets tableau project/earthquake_database.csv\",header=True,inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------+--------+---------+----------+-----+-----------+----------------------+---------+--------------+---------------+--------------------------+-------------+-------------------+----------------+----------------+---------------+---------+---------------+----------------+---------+\n",
      "|      Date|    Time|Latitude|Longitude|      Type|Depth|Depth Error|Depth Seismic Stations|Magnitude|Magnitude Type|Magnitude Error|Magnitude Seismic Stations|Azimuthal Gap|Horizontal Distance|Horizontal Error|Root Mean Square|             ID|   Source|Location Source|Magnitude Source|   Status|\n",
      "+----------+--------+--------+---------+----------+-----+-----------+----------------------+---------+--------------+---------------+--------------------------+-------------+-------------------+----------------+----------------+---------------+---------+---------------+----------------+---------+\n",
      "|01/02/1965|13:44:18|  19.246|  145.616|Earthquake|131.6|       null|                  null|      6.0|            MW|           null|                      null|         null|               null|            null|            null|   ISCGEM860706|   ISCGEM|         ISCGEM|          ISCGEM|Automatic|\n",
      "|01/04/1965|11:29:49|   1.863|  127.352|Earthquake| 80.0|       null|                  null|      5.8|            MW|           null|                      null|         null|               null|            null|            null|   ISCGEM860737|   ISCGEM|         ISCGEM|          ISCGEM|Automatic|\n",
      "|01/05/1965|18:05:58| -20.579| -173.972|Earthquake| 20.0|       null|                  null|      6.2|            MW|           null|                      null|         null|               null|            null|            null|   ISCGEM860762|   ISCGEM|         ISCGEM|          ISCGEM|Automatic|\n",
      "|01/08/1965|18:49:43| -59.076|  -23.557|Earthquake| 15.0|       null|                  null|      5.8|            MW|           null|                      null|         null|               null|            null|            null|   ISCGEM860856|   ISCGEM|         ISCGEM|          ISCGEM|Automatic|\n",
      "|01/09/1965|13:32:50|  11.938|  126.427|Earthquake| 15.0|       null|                  null|      5.8|            MW|           null|                      null|         null|               null|            null|            null|   ISCGEM860890|   ISCGEM|         ISCGEM|          ISCGEM|Automatic|\n",
      "|01/10/1965|13:36:32| -13.405|  166.629|Earthquake| 35.0|       null|                  null|      6.7|            MW|           null|                      null|         null|               null|            null|            null|   ISCGEM860922|   ISCGEM|         ISCGEM|          ISCGEM|Automatic|\n",
      "|01/12/1965|13:32:25|  27.357|   87.867|Earthquake| 20.0|       null|                  null|      5.9|            MW|           null|                      null|         null|               null|            null|            null|   ISCGEM861007|   ISCGEM|         ISCGEM|          ISCGEM|Automatic|\n",
      "|01/15/1965|23:17:42| -13.309|  166.212|Earthquake| 35.0|       null|                  null|      6.0|            MW|           null|                      null|         null|               null|            null|            null|   ISCGEM861111|   ISCGEM|         ISCGEM|          ISCGEM|Automatic|\n",
      "|01/16/1965|11:32:37| -56.452|  -27.043|Earthquake| 95.0|       null|                  null|      6.0|            MW|           null|                      null|         null|               null|            null|            null|ISCGEMSUP861125|ISCGEMSUP|         ISCGEM|          ISCGEM|Automatic|\n",
      "|01/17/1965|10:43:17| -24.563|  178.487|Earthquake|565.0|       null|                  null|      5.8|            MW|           null|                      null|         null|               null|            null|            null|   ISCGEM861148|   ISCGEM|         ISCGEM|          ISCGEM|Automatic|\n",
      "+----------+--------+--------+---------+----------+-----+-----------+----------------------+---------+--------------+---------------+--------------------------+-------------+-------------------+----------------+----------------+---------------+---------+---------------+----------------+---------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "eq.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Date: string (nullable = true)\n",
      " |-- Time: string (nullable = true)\n",
      " |-- Latitude: double (nullable = true)\n",
      " |-- Longitude: double (nullable = true)\n",
      " |-- Type: string (nullable = true)\n",
      " |-- Depth: double (nullable = true)\n",
      " |-- Depth Error: double (nullable = true)\n",
      " |-- Depth Seismic Stations: integer (nullable = true)\n",
      " |-- Magnitude: double (nullable = true)\n",
      " |-- Magnitude Type: string (nullable = true)\n",
      " |-- Magnitude Error: double (nullable = true)\n",
      " |-- Magnitude Seismic Stations: integer (nullable = true)\n",
      " |-- Azimuthal Gap: double (nullable = true)\n",
      " |-- Horizontal Distance: double (nullable = true)\n",
      " |-- Horizontal Error: double (nullable = true)\n",
      " |-- Root Mean Square: double (nullable = true)\n",
      " |-- ID: string (nullable = true)\n",
      " |-- Source: string (nullable = true)\n",
      " |-- Location Source: string (nullable = true)\n",
      " |-- Magnitude Source: string (nullable = true)\n",
      " |-- Status: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "eq.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Date', 'string'),\n",
       " ('Time', 'string'),\n",
       " ('Latitude', 'double'),\n",
       " ('Longitude', 'double'),\n",
       " ('Type', 'string'),\n",
       " ('Depth', 'double'),\n",
       " ('Depth Error', 'double'),\n",
       " ('Depth Seismic Stations', 'int'),\n",
       " ('Magnitude', 'double'),\n",
       " ('Magnitude Type', 'string'),\n",
       " ('Magnitude Error', 'double'),\n",
       " ('Magnitude Seismic Stations', 'int'),\n",
       " ('Azimuthal Gap', 'double'),\n",
       " ('Horizontal Distance', 'double'),\n",
       " ('Horizontal Error', 'double'),\n",
       " ('Root Mean Square', 'double'),\n",
       " ('ID', 'string'),\n",
       " ('Source', 'string'),\n",
       " ('Location Source', 'string'),\n",
       " ('Magnitude Source', 'string'),\n",
       " ('Status', 'string')]"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eq.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType,StructField,IntegerType,DoubleType,FloatType,StringType,DateType\n",
    "customschema= StructType([\n",
    "    StructField('event_date',StringType(),True),\n",
    "    StructField('event_time',StringType(),True),\n",
    "    StructField('Latitude',DoubleType(),True),\n",
    "    StructField('Longitude',DoubleType(),True),\n",
    "    StructField('Type',StringType(),True),\n",
    "    StructField('Depth',DoubleType(),True),\n",
    "    StructField('Depth_Error',DoubleType(),True),\n",
    "    StructField('Depth_Seismic_Stations',DoubleType(),True),\n",
    "    StructField('Magnitude',FloatType(),True),\n",
    "    StructField('Magnitude_Type',StringType(),True),\n",
    "    StructField('Magnitude_Error',DoubleType(),True),\n",
    "    StructField('Magnitude_Seismic_Stations',IntegerType(),True),\n",
    "    StructField('Azimuthal_Gap',DoubleType(),True),\n",
    "    StructField('Horizontal_Distance',DoubleType(),True),\n",
    "    StructField('Horizontal_Error',DoubleType(),True),\n",
    "    StructField('Root_Mean_Square',DoubleType(),True),\n",
    "    StructField('ID',StringType(),True),\n",
    "    StructField('Source',StringType(),True),\n",
    "    StructField('Location_Source',StringType(),True),\n",
    "    StructField('Magnitude_Source',StringType(),True),\n",
    "    StructField('Status',StringType(),True)\n",
    "])\n",
    "eq=spark.read.csv(\"C:/Users/krish/OneDrive/Documents/UoH/datasets tableau project/earthquake_database.csv\",header=True,schema=customschema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+--------+---------+----------+-----+-----------+----------------------+---------+--------------+---------------+--------------------------+-------------+-------------------+----------------+----------------+------------+------+---------------+----------------+---------+\n",
      "|event_date|event_time|Latitude|Longitude|      Type|Depth|Depth_Error|Depth_Seismic_Stations|Magnitude|Magnitude_Type|Magnitude_Error|Magnitude_Seismic_Stations|Azimuthal_Gap|Horizontal_Distance|Horizontal_Error|Root_Mean_Square|          ID|Source|Location_Source|Magnitude_Source|   Status|\n",
      "+----------+----------+--------+---------+----------+-----+-----------+----------------------+---------+--------------+---------------+--------------------------+-------------+-------------------+----------------+----------------+------------+------+---------------+----------------+---------+\n",
      "|01/02/1965|  13:44:18|  19.246|  145.616|Earthquake|131.6|       null|                  null|      6.0|            MW|           null|                      null|         null|               null|            null|            null|ISCGEM860706|ISCGEM|         ISCGEM|          ISCGEM|Automatic|\n",
      "|01/04/1965|  11:29:49|   1.863|  127.352|Earthquake| 80.0|       null|                  null|      5.8|            MW|           null|                      null|         null|               null|            null|            null|ISCGEM860737|ISCGEM|         ISCGEM|          ISCGEM|Automatic|\n",
      "|01/05/1965|  18:05:58| -20.579| -173.972|Earthquake| 20.0|       null|                  null|      6.2|            MW|           null|                      null|         null|               null|            null|            null|ISCGEM860762|ISCGEM|         ISCGEM|          ISCGEM|Automatic|\n",
      "|01/08/1965|  18:49:43| -59.076|  -23.557|Earthquake| 15.0|       null|                  null|      5.8|            MW|           null|                      null|         null|               null|            null|            null|ISCGEM860856|ISCGEM|         ISCGEM|          ISCGEM|Automatic|\n",
      "|01/09/1965|  13:32:50|  11.938|  126.427|Earthquake| 15.0|       null|                  null|      5.8|            MW|           null|                      null|         null|               null|            null|            null|ISCGEM860890|ISCGEM|         ISCGEM|          ISCGEM|Automatic|\n",
      "+----------+----------+--------+---------+----------+-----+-----------+----------------------+---------+--------------+---------------+--------------------------+-------------+-------------------+----------------+----------------+------------+------+---------------+----------------+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "eq.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from pyspark.sql.functions import *\n",
    "#eq1.select(eq1.event_date).distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|      Date|\n",
      "+----------+\n",
      "|01/01/1967|\n",
      "|01/01/1969|\n",
      "|01/01/1970|\n",
      "|01/01/1971|\n",
      "|01/01/1972|\n",
      "+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "eq.select(eq.Date).distinct().orderBy(eq.Date.asc()).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "eq.createOrReplaceTempView(\"equake\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+---------------+-----+---------+---------+\n",
      "|event_Date|event_time|location_source|depth|   source|   status|\n",
      "+----------+----------+---------------+-----+---------+---------+\n",
      "|07/02/1965|  20:58:40|         ISCGEM| 45.0|   ISCGEM|Automatic|\n",
      "|08/11/1965|  22:31:51|         ISCGEM| 30.0|   ISCGEM|Automatic|\n",
      "|09/08/1966|  21:15:56|         ISCGEM|115.0|ISCGEMSUP|Automatic|\n",
      "|10/17/1966|  21:42:00|         ISCGEM| 40.0|   ISCGEM|Automatic|\n",
      "|12/31/1966|  22:15:19|         ISCGEM| 35.0|   ISCGEM|Automatic|\n",
      "|02/19/1968|  22:45:45|         ISCGEM| 15.0|   ISCGEM|Automatic|\n",
      "|08/01/1968|  20:19:22|         ISCGEM| 25.0|   ISCGEM|Automatic|\n",
      "|08/14/1968|  22:14:23|         ISCGEM| 20.0|   ISCGEM|Automatic|\n",
      "|02/10/1969|  22:58:06|         ISCGEM|660.0|   ISCGEM|Automatic|\n",
      "|02/11/1969|  22:16:13|         ISCGEM|430.5|   ISCGEM|Automatic|\n",
      "|08/11/1969|  21:27:40|         ISCGEM| 25.0|ISCGEMSUP|Automatic|\n",
      "|11/22/1969|  23:09:40|         ISCGEM| 35.0|   ISCGEM|Automatic|\n",
      "|12/25/1969|  21:32:31|         ISCGEM| 20.0|   ISCGEM|Automatic|\n",
      "|05/31/1970|  20:23:29|         ISCGEM| 45.0|   ISCGEM|Automatic|\n",
      "|02/14/1972|  23:29:53|         ISCGEM|101.8|   ISCGEM|Automatic|\n",
      "|04/28/1972|  23:32:11|         ISCGEM|409.9|   ISCGEM|Automatic|\n",
      "|05/22/1972|  20:45:57|         ISCGEM|222.1|   ISCGEM|Automatic|\n",
      "|07/30/1972|  21:45:17|         ISCGEM| 25.0|   ISCGEM|Automatic|\n",
      "|08/17/1972|  23:44:09|         ISCGEM| 20.0|   ISCGEM|Automatic|\n",
      "|01/30/1973|  21:01:12|             US| 43.0|       US| Reviewed|\n",
      "+----------+----------+---------------+-----+---------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import *\n",
    "query1= spark.sql(\"select event_Date,event_time,location_source,depth,source,status from equake where magnitude>7 and hour(event_time) between 20 and 24\")\n",
    "query1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+\n",
      "|location_source|\n",
      "+---------------+\n",
      "|             CI|\n",
      "|            CAR|\n",
      "|            MDD|\n",
      "|            UCR|\n",
      "|           GCMT|\n",
      "|         ISCGEM|\n",
      "|            OTT|\n",
      "|           RSPR|\n",
      "|           CASC|\n",
      "|             UW|\n",
      "|            ROM|\n",
      "|            TEH|\n",
      "|              B|\n",
      "|            SJA|\n",
      "|            BOU|\n",
      "|           AEIC|\n",
      "|            ATH|\n",
      "|            JMA|\n",
      "|              U|\n",
      "|            TUL|\n",
      "+---------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "eq.select('location_source').distinct().show()\n",
    "\n",
    "#df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['event_date',\n",
       " 'event_time',\n",
       " 'Latitude',\n",
       " 'Longitude',\n",
       " 'Type',\n",
       " 'Depth',\n",
       " 'Depth_Error',\n",
       " 'Depth_Seismic_Stations',\n",
       " 'Magnitude',\n",
       " 'Magnitude_Type',\n",
       " 'Magnitude_Error',\n",
       " 'Magnitude_Seismic_Stations',\n",
       " 'Azimuthal_Gap',\n",
       " 'Horizontal_Distance',\n",
       " 'Horizontal_Error',\n",
       " 'Root_Mean_Square',\n",
       " 'ID',\n",
       " 'Source',\n",
       " 'Location_Source',\n",
       " 'Magnitude_Source',\n",
       " 'Status']"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eq.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import pyspark.sql.functions as sqlfunc\n",
    "#split_col = sqlfunc.split(df['Date'], 'T')\n",
    "#df1 = eq.withColumn('date1', split_col.getItem(0))\n",
    "#df1 = eq.withColumn('date2', split_col.getItem(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df1.select(df1['date2']).distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df1.filter(df1['Date'].like('%T%')).select(df1['Date']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nd=eq.withColumn(\"newdate\", split(\"Date\", \"T\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nd.filter(nd['newdate'].like('%T%')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|          event_date|\n",
      "+--------------------+\n",
      "|1975-02-23T02:58:...|\n",
      "|1985-04-28T02:53:...|\n",
      "|2011-03-13T02:23:...|\n",
      "+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "eq.select('event_date').where('event_date like \"%T%\"').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q2= spark.sql(\"select Date from equake where Date like '%T%'\")\n",
    "q2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q2.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+--------+---------+----+-----+-----------+----------------------+---------+--------------+---------------+--------------------------+-------------+-------------------+----------------+----------------+---+------+---------------+----------------+------+\n",
      "|event_date|event_time|Latitude|Longitude|Type|Depth|Depth_Error|Depth_Seismic_Stations|Magnitude|Magnitude_Type|Magnitude_Error|Magnitude_Seismic_Stations|Azimuthal_Gap|Horizontal_Distance|Horizontal_Error|Root_Mean_Square| ID|Source|Location_Source|Magnitude_Source|Status|\n",
      "+----------+----------+--------+---------+----+-----+-----------+----------------------+---------+--------------+---------------+--------------------------+-------------+-------------------+----------------+----------------+---+------+---------------+----------------+------+\n",
      "|         0|         0|       0|        0|   0|    0|      18951|                 16315|        0|             3|          23085|                     20848|        16113|              21808|           22256|            6060|  0|     0|              0|               0|     0|\n",
      "+----------+----------+--------+---------+----+-----+-----------+----------------------+---------+--------------+---------------+--------------------------+-------------+-------------------+----------------+----------------+---+------+---------------+----------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "eq.select([count(when(col(c).isNull(),c)).alias(c) for c in eq.columns]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+--------+---------+----+-----+-----------+----------------------+---------+--------------+---------------+--------------------------+-------------+-------------------+----------------+----------------+---+------+---------------+----------------+------+\n",
      "|event_date|event_time|Latitude|Longitude|Type|Depth|Depth_Error|Depth_Seismic_Stations|Magnitude|Magnitude_Type|Magnitude_Error|Magnitude_Seismic_Stations|Azimuthal_Gap|Horizontal_Distance|Horizontal_Error|Root_Mean_Square| ID|Source|Location_Source|Magnitude_Source|Status|\n",
      "+----------+----------+--------+---------+----+-----+-----------+----------------------+---------+--------------+---------------+--------------------------+-------------+-------------------+----------------+----------------+---+------+---------------+----------------+------+\n",
      "|         0|         0|       0|        0|   0|    0|          0|                     0|        0|             0|              0|                         0|            0|                  0|               0|               0|  0|     0|              0|               0|     0|\n",
      "+----------+----------+--------+---------+----+-----+-----------+----------------------+---------+--------------+---------------+--------------------------+-------------+-------------------+----------------+----------------+---+------+---------------+----------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "eq.select([count(when(isnan(c),c)).alias(c) for c in eq.columns]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
